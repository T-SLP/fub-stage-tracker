#!/usr/bin/env python3
"""
Weekly Agent Performance Report

Generates a Google Sheets report with agent metrics:
- Stage progression: Offers Made, Contracts Sent, Under Contract, Closed
- Call metrics from FUB API

Can be run automatically via GitHub Actions or manually triggered.
Sends email reports on Monday (weekly) and Wednesday (midweek).
"""

import os
import sys
import argparse
import base64
import json
import smtplib
import ssl
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
from typing import Dict, List, Any, Optional
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# Eastern timezone for week boundaries
EASTERN_TZ = ZoneInfo("America/New_York")
from pathlib import Path

# Load .env file from project root (for local development)
try:
    from dotenv import load_dotenv
    # Look for .env in parent directory (project root)
    env_path = Path(__file__).resolve().parent.parent / '.env'
    load_dotenv(env_path)
except ImportError:
    pass  # dotenv not required in production (GitHub Actions)

import psycopg2
import psycopg2.extras
import requests
import gspread
from google.oauth2.service_account import Credentials

# Configuration from environment
SUPABASE_DB_URL = os.getenv("SUPABASE_DB_URL")
FUB_API_KEY = os.getenv("FUB_API_KEY")
GOOGLE_SHEETS_CREDENTIALS = os.getenv("GOOGLE_SHEETS_CREDENTIALS")  # JSON string
# Weekly Agent Report spreadsheet ID
WEEKLY_AGENT_SHEET_ID = "1MNnP-w70h7gv7NnpRxO6GZstq9m6wW5USAozzCev6gs"

# Stage names to track (must match exactly what's in the database)
TRACKED_STAGES = [
    "ACQ - Offers Made",
    "ACQ - Contract Sent",
    "ACQ - Under Contract",
    "Closed",
    "ACQ - Closed Won",
]

# Agents to include in the report (others will be filtered out)
# Set to None to include all agents
INCLUDED_AGENTS = [
    "Dante Hernandez",
    "Madeleine Penales",
]

# Email configuration
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587
EMAIL_FROM = os.getenv("EMAIL_FROM", "travis@synergylandpartners.com")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")  # Gmail app password
EMAIL_TO = ["acquisitions@synergylandpartners.com", "dante@synergylandpartners.com"]
EMAIL_CC = ["travis@synergylandpartners.com"]


def get_date_range(days_back: int = None, previous_week: bool = False) -> tuple[datetime, datetime]:
    """
    Calculate the date range for the report.

    Modes:
    - previous_week=True: Returns the full previous week (Mon 00:00 to Sun 23:59 Eastern)
    - days_back specified: Simple "last N days" calculation
    - Default (auto): On Monday, returns previous week. Otherwise, returns current week so far.

    All modes use Monday-Sunday week boundaries in Eastern timezone to match FUB's standard report format.
    """
    # Use Eastern timezone for week boundaries
    now_eastern = datetime.now(EASTERN_TZ)

    if days_back is not None:
        # Legacy behavior: simple days-back calculation
        end_date = now_eastern
        start_date = end_date - timedelta(days=days_back)
        return start_date, end_date

    # weekday() returns 0 for Monday, 6 for Sunday
    days_since_monday = now_eastern.weekday()

    # Determine if we should report on previous week
    # On Monday (weekday=0), auto mode reports the previous full week
    use_previous_week = previous_week or (days_since_monday == 0)

    if use_previous_week:
        # Previous week: Monday through Sunday of last week
        # First, find the start of the current week (Monday 00:00 Eastern)
        start_of_current_week = now_eastern - timedelta(days=days_since_monday)
        start_of_current_week = start_of_current_week.replace(hour=0, minute=0, second=0, microsecond=0)

        # Previous week starts 7 days before current week
        start_date = start_of_current_week - timedelta(days=7)

        # Previous week ends at the end of Sunday (start of current week)
        end_date = start_of_current_week
    else:
        # Current week: Monday through now
        start_of_week = now_eastern - timedelta(days=days_since_monday)
        start_date = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)
        end_date = now_eastern

    return start_date, end_date


def query_open_offers_metrics(fub_api_key: str) -> Dict[str, Dict[str, Any]]:
    """
    Query open offers and calculate follow-up metrics as percentages.

    Returns per-agent metrics:
    - total_open_offers: Total leads in "Offers Made" or "Contract Sent" (24+ hrs)
    - low_followup_pct: % of open offers with 0, 1, or 2 follow-up calls (need more outreach)
    - low_connection_pct: % of open offers with 0 or 1 connections/2+ min calls (need more engagement)

    Criteria for open offers:
    - Lead is currently in "ACQ - Offers Made" or "ACQ - Contract Sent" stage
    - Lead has been in this stage for 24+ hours (exclude immediate declines)

    Returns: {agent_name: {'total': N, 'low_followup_pct': 'X%', 'low_connection_pct': 'Y%'}, ...}
    """
    if not SUPABASE_DB_URL:
        return {}

    conn = psycopg2.connect(SUPABASE_DB_URL, sslmode='require')

    # Get all leads currently in open offer stages (24+ hours old)
    twenty_four_hours_ago = datetime.now(EASTERN_TZ) - timedelta(hours=24)

    try:
        with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
            cur.execute("""
                WITH latest_stages AS (
                    SELECT DISTINCT ON (person_id)
                        person_id,
                        stage_to,
                        changed_at,
                        COALESCE(
                            assigned_user_name,
                            raw_payload->>'assignedTo',
                            CASE WHEN changed_at < '2025-12-19' THEN 'Madeleine Penales' ELSE 'Unassigned' END
                        ) as agent
                    FROM stage_changes
                    ORDER BY person_id, changed_at DESC
                ),
                offer_dates AS (
                    SELECT DISTINCT ON (person_id)
                        person_id,
                        changed_at as offer_date
                    FROM stage_changes
                    WHERE stage_to = 'ACQ - Offers Made'
                    ORDER BY person_id, changed_at
                )
                SELECT
                    ls.person_id,
                    ls.agent,
                    od.offer_date
                FROM latest_stages ls
                JOIN offer_dates od ON ls.person_id = od.person_id
                WHERE ls.stage_to IN ('ACQ - Offers Made', 'ACQ - Contract Sent')
                  AND ls.changed_at < %s
            """, (twenty_four_hours_ago,))

            open_offers = []
            for row in cur.fetchall():
                open_offers.append({
                    'person_id': str(row['person_id']),
                    'agent': row['agent'],
                    'offer_date': row['offer_date'],
                })
    finally:
        conn.close()

    if not open_offers or not fub_api_key:
        return {}

    # Fetch calls to determine follow-up counts
    auth_string = base64.b64encode(f'{fub_api_key}:'.encode()).decode()

    earliest_offer = min(o['offer_date'] for o in open_offers)
    start_str = (earliest_offer - timedelta(days=1)).strftime('%Y-%m-%d')
    end_str = (datetime.now(EASTERN_TZ) + timedelta(days=1)).strftime('%Y-%m-%d')

    all_calls = []
    offset = 0
    limit = 100

    while True:
        try:
            response = requests.get(
                'https://api.followupboss.com/v1/calls',
                params={
                    'createdAfter': start_str,
                    'createdBefore': end_str,
                    'limit': limit,
                    'offset': offset
                },
                headers={
                    'Authorization': f'Basic {auth_string}',
                    'Content-Type': 'application/json'
                },
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                calls = data.get('calls', [])
                all_calls.extend(calls)

                if len(calls) < limit:
                    break
                offset += limit
            else:
                break
        except Exception:
            break

    # Build maps of person_id -> calls and connections after offer date
    target_person_ids = {o['person_id'] for o in open_offers}
    offer_dates_map = {o['person_id']: o['offer_date'] for o in open_offers}

    calls_after_offer = {pid: 0 for pid in target_person_ids}
    connections_after_offer = {pid: 0 for pid in target_person_ids}

    for call in all_calls:
        person_id = call.get('personId')
        if not person_id:
            continue

        person_id_str = str(person_id)
        if person_id_str not in target_person_ids:
            continue

        # Only count outbound calls
        if call.get('isIncoming') == True:
            continue

        created = call.get('created')
        if not created:
            continue

        try:
            call_date = datetime.fromisoformat(created.replace('Z', '+00:00')).date()
            offer_date = offer_dates_map[person_id_str]
            if hasattr(offer_date, 'date'):
                offer_date = offer_date.date()

            if call_date >= offer_date:
                calls_after_offer[person_id_str] += 1
                # Also count connections (2+ min = 120+ seconds)
                duration = call.get('duration', 0) or 0
                if duration >= 120:
                    connections_after_offer[person_id_str] += 1
        except Exception:
            continue

    # Calculate per-agent metrics
    agent_totals = {}
    agent_low_followup = {}
    agent_low_connection = {}

    for offer in open_offers:
        agent = offer['agent']
        person_id = offer['person_id']
        followup_count = calls_after_offer.get(person_id, 0)
        connection_count = connections_after_offer.get(person_id, 0)

        agent_totals[agent] = agent_totals.get(agent, 0) + 1

        # Count leads with 0, 1, or 2 follow-up calls (need more outreach)
        if followup_count <= 2:
            agent_low_followup[agent] = agent_low_followup.get(agent, 0) + 1

        # Count leads with 0 or 1 connections (need more engagement)
        if connection_count <= 1:
            agent_low_connection[agent] = agent_low_connection.get(agent, 0) + 1

    # Build result with percentages
    result = {}
    for agent in agent_totals:
        total = agent_totals[agent]
        low_followup = agent_low_followup.get(agent, 0)
        low_connection = agent_low_connection.get(agent, 0)

        low_followup_pct = round(low_followup / total * 100) if total > 0 else 0
        low_connection_pct = round(low_connection / total * 100) if total > 0 else 0

        result[agent] = {
            'total': total,
            'low_followup_count': low_followup,
            'low_followup_pct': f"{low_followup_pct}%",
            'low_connection_count': low_connection,
            'low_connection_pct': f"{low_connection_pct}%",
        }

    return result


def query_stage_metrics(start_date: datetime, end_date: datetime) -> Dict[str, Dict[str, int]]:
    """
    Query Supabase for stage change metrics grouped by agent.
    Returns: {agent_name: {stage_name: count, ...}, ...}
    """
    if not SUPABASE_DB_URL:
        print("ERROR: SUPABASE_DB_URL not set")
        sys.exit(1)

    conn = psycopg2.connect(SUPABASE_DB_URL, sslmode='require')
    metrics = {}

    try:
        with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
            # Query stage changes within date range, grouped by agent and stage
            # Use COALESCE to fall back to raw_payload->>'assignedTo' for older records
            # where assigned_user_name wasn't populated.
            # For records before Dec 19, 2025 with no agent info, default to Madeleine Penales
            # (she was the only acquisition agent at that time)
            # Count DISTINCT person_id to avoid counting the same lead multiple times
            # (e.g., if a lead moves out of and back into a stage)
            cur.execute("""
                SELECT
                    COALESCE(
                        assigned_user_name,
                        raw_payload->>'assignedTo',
                        CASE WHEN changed_at < '2025-12-19' THEN 'Madeleine Penales' ELSE 'Unassigned' END
                    ) as agent,
                    stage_to,
                    COUNT(DISTINCT person_id) as count
                FROM stage_changes
                WHERE changed_at >= %s
                  AND changed_at < %s
                  AND stage_to IN %s
                GROUP BY COALESCE(
                    assigned_user_name,
                    raw_payload->>'assignedTo',
                    CASE WHEN changed_at < '2025-12-19' THEN 'Madeleine Penales' ELSE 'Unassigned' END
                ), stage_to
                ORDER BY 1, 2
            """, (start_date, end_date, tuple(TRACKED_STAGES)))

            for row in cur.fetchall():
                agent = row['agent']
                stage = row['stage_to']
                count = row['count']

                if agent not in metrics:
                    metrics[agent] = {s: 0 for s in TRACKED_STAGES}
                metrics[agent][stage] = count

    finally:
        conn.close()

    return metrics


def get_fub_users() -> Dict[str, int]:
    """
    Get mapping of FUB user names to IDs.
    Returns: {user_name: user_id, ...}
    """
    if not FUB_API_KEY:
        print("WARNING: FUB_API_KEY not set, skipping call metrics")
        return {}

    auth_string = base64.b64encode(f'{FUB_API_KEY}:'.encode()).decode()

    try:
        response = requests.get(
            'https://api.followupboss.com/v1/users',
            headers={
                'Authorization': f'Basic {auth_string}',
                'Content-Type': 'application/json'
            },
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            users = data.get('users', [])
            return {u.get('name', ''): u.get('id') for u in users if u.get('name')}
        else:
            print(f"WARNING: Failed to fetch FUB users: {response.status_code}")
            return {}

    except Exception as e:
        print(f"WARNING: Error fetching FUB users: {e}")
        return {}


def query_call_metrics(start_date: datetime, end_date: datetime, user_ids: Dict[str, int]) -> Dict[str, Dict[str, Any]]:
    """
    Query FUB API for detailed call metrics per agent.
    Note: FUB API doesn't filter by userId, so we fetch all calls and group client-side.
    Returns: {agent_name: {calls: int, connected: int, conversations: int, talk_time_min: int}, ...}
    """
    if not FUB_API_KEY or not user_ids:
        return {}

    auth_string = base64.b64encode(f'{FUB_API_KEY}:'.encode()).decode()

    # Format dates for FUB API
    start_str = start_date.strftime('%Y-%m-%d')
    end_str = end_date.strftime('%Y-%m-%d')

    # Fetch ALL calls for the date range (API doesn't filter by userId)
    all_calls = []
    offset = 0
    limit = 100

    print("  Fetching all calls from FUB API...")
    while True:
        try:
            response = requests.get(
                'https://api.followupboss.com/v1/calls',
                params={
                    'createdAfter': start_str,
                    'createdBefore': end_str,
                    'limit': limit,
                    'offset': offset
                },
                headers={
                    'Authorization': f'Basic {auth_string}',
                    'Content-Type': 'application/json'
                },
                timeout=30
            )

            if response.status_code == 200:
                data = response.json()
                calls = data.get('calls', [])
                all_calls.extend(calls)

                if len(calls) < limit:
                    break
                offset += limit
            else:
                print(f"WARNING: Failed to fetch calls: {response.status_code}")
                break
        except Exception as e:
            print(f"WARNING: Error fetching calls: {e}")
            break

    print(f"  Total calls fetched: {len(all_calls)}")

    # Build reverse lookup: userId -> userName
    user_id_to_name = {v: k for k, v in user_ids.items()}

    # Initialize metrics for all users
    call_metrics = {}
    for user_name in user_ids.keys():
        call_metrics[user_name] = {
            'outbound_calls': 0,
            'connected': 0,  # Outbound calls >= 1 min (for connection rate)
            'conversations': 0,  # All calls (inbound + outbound) >= 2 min
            'talk_time_min': 0,
            'long_call_durations': [],  # Track durations for calls >= 2 min to calculate average
            'outbound_call_details': [],  # For multi-dial sequence analysis
            'unique_leads_dialed': set(),  # Track unique personIds for leads dialed
            'unique_leads_connected': set(),  # Track unique personIds for conversations (2+ min)
            'single_dial_calls': 0,
            'single_dial_answered': 0,  # Single dials that resulted in 2+ min call
            'double_dial_sequences': 0,
            'double_dial_answered': 0,  # Double dial sequences that resulted in 2+ min call
            'triple_dial_sequences': 0,
            'multi_dial_calls': 0,  # Total calls that are part of any 2x+ sequence
        }

    # Group calls by userId and calculate metrics
    # FUB definitions (from https://help.followupboss.com/hc/en-us/articles/360014186693-Call-Reporting):
    # - Calls Made = Outgoing calls only (isIncoming=False)
    # - Connected = Calls with duration >= 60 seconds (1 minute)
    # - Conversations = ANY call (inbound or outbound) with duration >= 120 seconds (2 minutes)
    # - Talk Time = Total duration of all calls
    # Custom metric:
    # - Connection Rate = Connected / Outbound Calls (measures how often outbound calls reach someone)
    for call in all_calls:
        call_user_id = call.get('userId')
        call_user_name = call.get('userName')
        is_outgoing = call.get('isIncoming') == False
        duration = call.get('duration', 0) or 0

        # Try to match by userId first, then by userName
        agent_name = None
        if call_user_id in user_id_to_name:
            agent_name = user_id_to_name[call_user_id]
        elif call_user_name in user_ids:
            agent_name = call_user_name

        if agent_name and agent_name in call_metrics:
            # Only count outgoing calls as "Outbound Calls"
            if is_outgoing:
                call_metrics[agent_name]['outbound_calls'] += 1

                # Connected = outbound calls >= 1 min (used for connection rate)
                if duration >= 60:
                    call_metrics[agent_name]['connected'] += 1

                # Collect call details for multi-dial sequence analysis
                to_number = call.get('toNumber')
                created = call.get('created')
                if to_number and created:
                    call_metrics[agent_name]['outbound_call_details'].append({
                        'to_number': to_number,
                        'created': created,
                        'duration': duration,
                    })

                # Track unique leads dialed (by personId)
                person_id = call.get('personId')
                if person_id:
                    call_metrics[agent_name]['unique_leads_dialed'].add(person_id)

            # Conversations = ANY call (inbound or outbound) >= 2 min
            # This matches FUB's definition: "Calls lasting 2 minutes or more"
            if duration >= 120:
                call_metrics[agent_name]['conversations'] += 1
                # Track durations for average calculation
                call_metrics[agent_name]['long_call_durations'].append(duration)
                # Track unique leads with conversations
                person_id = call.get('personId')
                if person_id:
                    call_metrics[agent_name]['unique_leads_connected'].add(person_id)

            # Talk time includes all calls with duration
            if duration > 0:
                call_metrics[agent_name]['talk_time_min'] += duration

    # Convert total duration from seconds to minutes
    for agent_name in call_metrics:
        call_metrics[agent_name]['talk_time_min'] = call_metrics[agent_name]['talk_time_min'] // 60

    # Analyze multi-dial sequences for each agent
    # A sequence is consecutive calls to the same number with <= 2 min between each call
    for agent_name in call_metrics:
        calls = call_metrics[agent_name]['outbound_call_details']
        if not calls:
            # No calls - convert sets to counts and set defaults
            call_metrics[agent_name]['unique_leads_dialed'] = len(call_metrics[agent_name]['unique_leads_dialed'])
            call_metrics[agent_name]['unique_leads_connected'] = len(call_metrics[agent_name]['unique_leads_connected'])
            call_metrics[agent_name]['single_dial_calls'] = 0
            del call_metrics[agent_name]['outbound_call_details']
            continue

        # Sort calls by timestamp
        calls.sort(key=lambda x: x['created'])

        total_multi_dial_calls = 0
        single_dials = 0
        single_dial_answered = 0
        double_sequences = 0
        double_dial_answered = 0
        triple_sequences = 0

        i = 0
        while i < len(calls):
            current_number = calls[i]['to_number']
            sequence_calls = [calls[i]]
            sequence_length = 1

            j = i + 1
            while j < len(calls):
                # Parse timestamps and check time difference
                prev_time = datetime.fromisoformat(calls[j-1]['created'].replace('Z', '+00:00'))
                curr_time = datetime.fromisoformat(calls[j]['created'].replace('Z', '+00:00'))
                time_diff = (curr_time - prev_time).total_seconds()

                # Same number and within 2 minutes of previous call = part of sequence
                if calls[j]['to_number'] == current_number and time_diff <= 120:
                    sequence_calls.append(calls[j])
                    sequence_length += 1
                    j += 1
                else:
                    break

            # Check if any call in the sequence resulted in an answer (2+ min)
            sequence_answered = any(c.get('duration', 0) >= 120 for c in sequence_calls)

            # Count the sequence
            if sequence_length >= 3:
                triple_sequences += 1
                total_multi_dial_calls += sequence_length
            elif sequence_length == 2:
                double_sequences += 1
                total_multi_dial_calls += sequence_length
                if sequence_answered:
                    double_dial_answered += 1
            else:
                # Single dial
                single_dials += 1
                if sequence_answered:
                    single_dial_answered += 1

            # Move to next unprocessed call
            i = j if j > i + 1 else i + 1

        call_metrics[agent_name]['single_dial_calls'] = single_dials
        call_metrics[agent_name]['single_dial_answered'] = single_dial_answered
        call_metrics[agent_name]['double_dial_sequences'] = double_sequences
        call_metrics[agent_name]['double_dial_answered'] = double_dial_answered
        call_metrics[agent_name]['triple_dial_sequences'] = triple_sequences
        call_metrics[agent_name]['multi_dial_calls'] = total_multi_dial_calls

        # Convert unique leads sets to counts and clean up raw data
        call_metrics[agent_name]['unique_leads_dialed'] = len(call_metrics[agent_name]['unique_leads_dialed'])
        call_metrics[agent_name]['unique_leads_connected'] = len(call_metrics[agent_name]['unique_leads_connected'])
        del call_metrics[agent_name]['outbound_call_details']

    return call_metrics


def write_to_google_sheets(
    stage_metrics: Dict[str, Dict[str, int]],
    call_metrics: Dict[str, Dict[str, Any]],
    start_date: datetime,
    end_date: datetime,
    open_offers_metrics: Dict[str, Dict[str, Any]] = None
) -> str:
    """
    Write the report to Google Sheets with two tabs:
    - "Latest" tab: Current week's full report (overwritten each run)
    - "History" tab: Appends summary row per agent (most recent at top)

    Returns the URL to the spreadsheet.
    """
    if not GOOGLE_SHEETS_CREDENTIALS:
        print("ERROR: GOOGLE_SHEETS_CREDENTIALS not set")
        sys.exit(1)

    # Parse credentials from JSON string
    creds_dict = json.loads(GOOGLE_SHEETS_CREDENTIALS)

    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]

    credentials = Credentials.from_service_account_info(creds_dict, scopes=scopes)
    client = gspread.authorize(credentials)

    # Open the spreadsheet
    spreadsheet = client.open_by_key(WEEKLY_AGENT_SHEET_ID)
    existing_tabs = [ws.title for ws in spreadsheet.worksheets()]

    # Prepare header row for History tab (includes week column)
    history_headers = [
        "Week Starting",
        "Agent",
        # KPIs
        "Offers Made",
        "Contracts Sent",
        "% Open Offers w/ <= 2 Dials After Offer",
        # Metrics
        "Talk Time (min)",
        "Outbound Calls",
        "Connections (2+ min)",
        "Connection Rate",
        "Unique Leads Dialed",
        "Unique Leads Connected",
        "Unique Lead Connection Rate",
        "Avg Call (min)",
        "Single Dial",
        "2x Dial",
        "% Open Offers w/ <=1 Connection After Offer",
        "Signed Contracts",
    ]

    # Collect agent data - filter to included agents only
    all_agents = set(stage_metrics.keys()) | set(call_metrics.keys())
    all_agents.discard('Unassigned')

    # Filter agents if INCLUDED_AGENTS is set
    if INCLUDED_AGENTS:
        all_agents = [a for a in sorted(all_agents) if a in INCLUDED_AGENTS]
    else:
        all_agents = sorted(all_agents)

    week_label = start_date.strftime('%Y-%m-%d')

    # Collect data for each agent
    agent_data = {}
    history_rows_to_add = []

    for agent in all_agents:
        stage_data = stage_metrics.get(agent, {})
        offers = stage_data.get("ACQ - Offers Made", 0)
        contracts_sent = stage_data.get("ACQ - Contract Sent", 0)
        signed_contracts = stage_data.get("ACQ - Under Contract", 0)

        call_data = call_metrics.get(agent, {})
        outbound_calls = call_data.get('outbound_calls', 0)
        unique_leads = call_data.get('unique_leads_dialed', 0)
        unique_leads_connected = call_data.get('unique_leads_connected', 0)
        connections = call_data.get('conversations', 0)  # Calls >= 2 min
        long_call_durations = call_data.get('long_call_durations', [])
        avg_call_min = round(sum(long_call_durations) / len(long_call_durations) / 60, 1) if long_call_durations else 0
        talk_time = call_data.get('talk_time_min', 0)
        # Connection Rate uses 2+ min threshold (connections / outbound calls)
        connection_rate = f"{round(connections / outbound_calls * 100)}%" if outbound_calls > 0 else "0%"
        # Unique Lead Connection Rate
        unique_lead_conn_rate = f"{round(unique_leads_connected / unique_leads * 100)}%" if unique_leads > 0 else "0%"
        single_dial = call_data.get('single_dial_calls', 0)
        single_dial_answered = call_data.get('single_dial_answered', 0)
        double_dial = call_data.get('double_dial_sequences', 0)
        double_dial_answered = call_data.get('double_dial_answered', 0)

        # Calculate answer rates for dial sequences
        single_dial_rate = round(single_dial_answered / single_dial * 100) if single_dial > 0 else 0
        double_dial_rate = round(double_dial_answered / double_dial * 100) if double_dial > 0 else 0

        # Format with answer rate in parentheses
        single_dial_with_rate = f"{single_dial} ({single_dial_rate}%)"
        double_dial_with_rate = f"{double_dial} ({double_dial_rate}%)"

        # Open offers follow-up metrics (as percentages)
        agent_offer_metrics = open_offers_metrics.get(agent, {}) if open_offers_metrics else {}
        low_followup_pct = agent_offer_metrics.get('low_followup_pct', '0%')
        low_conn_pct = agent_offer_metrics.get('low_connection_pct', '0%')

        # Store all metrics for this agent
        agent_data[agent] = {
            # KPIs
            'talk_time': talk_time,
            'offers': offers,
            'contracts_sent': contracts_sent,
            'low_followup_pct': low_followup_pct,
            # Metrics
            'outbound_calls': outbound_calls,
            'connections': connections,
            'connection_rate': connection_rate,
            'unique_leads': unique_leads,
            'unique_leads_connected': unique_leads_connected,
            'unique_lead_conn_rate': unique_lead_conn_rate,
            'avg_call_min': avg_call_min,
            'long_call_total_sec': sum(long_call_durations),  # For proper total avg calculation
            'long_call_count': len(long_call_durations),      # For proper total avg calculation
            'single_dial': single_dial,
            'single_dial_with_rate': single_dial_with_rate,
            'double_dial': double_dial,
            'double_dial_with_rate': double_dial_with_rate,
            'low_conn_pct': low_conn_pct,
            'signed_contracts': signed_contracts,
        }

        # Row for History tab (with week column)
        # Must match order of history_headers exactly
        history_row = [
            week_label, agent, offers, contracts_sent, low_followup_pct,
            talk_time, outbound_calls, connections, connection_rate,
            unique_leads, unique_leads_connected, unique_lead_conn_rate,
            avg_call_min, single_dial, double_dial, low_conn_pct, signed_contracts
        ]
        history_rows_to_add.append(history_row)

    # === Write to "Latest" tab ===
    print("  Writing to 'Latest' tab...")
    if "Latest" in existing_tabs:
        latest_ws = spreadsheet.worksheet("Latest")
        latest_ws.clear()
    else:
        latest_ws = spreadsheet.add_worksheet(title="Latest", rows=100, cols=20, index=0)

    # Calculate totals across all agents
    totals = {
        'offers': sum(agent_data[agent]['offers'] for agent in all_agents),
        'contracts_sent': sum(agent_data[agent]['contracts_sent'] for agent in all_agents),
        'talk_time': sum(agent_data[agent]['talk_time'] for agent in all_agents),
        'outbound_calls': sum(agent_data[agent]['outbound_calls'] for agent in all_agents),
        'connections': sum(agent_data[agent]['connections'] for agent in all_agents),
        'unique_leads': sum(agent_data[agent]['unique_leads'] for agent in all_agents),
        'unique_leads_connected': sum(agent_data[agent]['unique_leads_connected'] for agent in all_agents),
        'single_dial': sum(agent_data[agent]['single_dial'] for agent in all_agents),
        'double_dial': sum(agent_data[agent]['double_dial'] for agent in all_agents),
        'signed_contracts': sum(agent_data[agent]['signed_contracts'] for agent in all_agents),
        'long_call_total_sec': sum(agent_data[agent]['long_call_total_sec'] for agent in all_agents),
        'long_call_count': sum(agent_data[agent]['long_call_count'] for agent in all_agents),
    }
    # Calculate rates from totals (not averaging rates)
    totals['connection_rate'] = f"{round(totals['connections'] / totals['outbound_calls'] * 100)}%" if totals['outbound_calls'] > 0 else "0%"
    totals['unique_lead_conn_rate'] = f"{round(totals['unique_leads_connected'] / totals['unique_leads'] * 100)}%" if totals['unique_leads'] > 0 else "0%"
    # Avg Call (min) = average duration of 2+ min calls only (matches agent-level calculation)
    totals['avg_call_min'] = round(totals['long_call_total_sec'] / totals['long_call_count'] / 60, 1) if totals['long_call_count'] > 0 else 0
    # For dial sequences with answer rates, sum the counts (rates don't sum meaningfully)
    totals['single_dial_with_rate'] = totals['single_dial']
    totals['double_dial_with_rate'] = totals['double_dial']

    # Calculate overall open offers percentages from raw counts
    total_open_offers = sum(m['total'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
    total_low_followup = sum(m['low_followup_count'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
    total_low_conn = sum(m['low_connection_count'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
    totals['low_followup_pct'] = f"{round(total_low_followup / total_open_offers * 100)}%" if total_open_offers > 0 else "0%"
    totals['low_conn_pct'] = f"{round(total_low_conn / total_open_offers * 100)}%" if total_open_offers > 0 else "0%"

    # Standards (expected minimums per agent)
    standards = {
        'offers': 18,
        'contracts_sent': 4,
        'low_followup_pct': "< 20%",  # Lower is better - target under 20%
        'talk_time': 220,
        'outbound_calls': 160,
        'connections': 30,
        'connection_rate': "-",
        'unique_leads': 50,
        'unique_leads_connected': "-",
        'unique_lead_conn_rate': "-",
        'avg_call_min': "-",
        'single_dial_with_rate': "-",
        'double_dial_with_rate': "-",
        'low_conn_pct': "< 75%",  # Lower is better - target under 75%
        'signed_contracts': 1,
    }

    # Build the Latest tab with exact formatting from user's template
    latest_rows = []

    # Row 1: Empty cell, then agent names, Total (Actuals), Standards (each AM)
    header_row = [""] + list(all_agents) + ["Total (Actuals)", "Standards (each AM)"]
    latest_rows.append(header_row)

    # Row 2: "KPIs" section header
    latest_rows.append(["KPIs"])

    # KPI rows
    kpi_metrics = [
        ("Offers Made", 'offers'),
        ("Contracts Sent", 'contracts_sent'),
        ("% Open Offers w/ <= 2 Dials After Offer", 'low_followup_pct'),
    ]
    for label, key in kpi_metrics:
        row = [label] + [agent_data[agent][key] for agent in all_agents] + [totals[key], standards[key]]
        latest_rows.append(row)

    # Empty row between sections
    latest_rows.append([""])

    # Row: "Metrics" section header
    latest_rows.append(["Metrics"])

    # Metrics rows (Talk Time moved here, 3x Dial removed)
    metric_items = [
        ("Talk Time (min)", 'talk_time'),
        ("Outbound Calls", 'outbound_calls'),
        ("Connections (2+ min)", 'connections'),
        ("Connection Rate", 'connection_rate'),
        ("Unique Leads Dialed", 'unique_leads'),
        ("Unique Leads Connected", 'unique_leads_connected'),
        ("Unique Lead Connection Rate", 'unique_lead_conn_rate'),
        ("Avg Call (min)", 'avg_call_min'),
        ("Single Dial", 'single_dial_with_rate'),
        ("2x Dial", 'double_dial_with_rate'),
        ("% Open Offers w/ <=1 Connection After Offer", 'low_conn_pct'),
        ("Signed Contracts", 'signed_contracts'),
    ]
    for label, key in metric_items:
        row = [label] + [agent_data[agent][key] for agent in all_agents] + [totals[key], standards[key]]
        latest_rows.append(row)

    # Empty row before metadata
    latest_rows.append([""])

    # Metadata rows
    # end_date is Monday 00:00, so subtract 1 day to show Sunday (actual last day of data)
    display_end_date = end_date - timedelta(days=1)
    latest_rows.append(["Report Generated:", datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')])
    latest_rows.append(["Date Range:", f"{start_date.strftime('%Y-%m-%d')} to {display_end_date.strftime('%Y-%m-%d')}"])

    latest_ws.update(latest_rows, 'A1')

    # Apply formatting to match user's template
    num_agents = len(all_agents)
    agent_last_col = chr(65 + num_agents)  # B for 1 agent, C for 2 agents, etc.
    total_col = chr(65 + num_agents + 1)   # Total column
    standards_col = chr(65 + num_agents + 2)  # Standards column

    # Row 1: Agent names, Total, Standards - bold and centered
    latest_ws.format(f'B1:{standards_col}1', {
        'textFormat': {'bold': True},
        'horizontalAlignment': 'CENTER'
    })

    # Row 2: "KPIs" - bold
    latest_ws.format('A2', {'textFormat': {'bold': True}})

    # Row 6: Empty row (no formatting needed)

    # Row 7: "Metrics" - bold
    latest_ws.format('A7', {'textFormat': {'bold': True}})

    # Metric labels (column A, rows 3-5 and 8-19): right-aligned
    latest_ws.format('A3:A5', {'horizontalAlignment': 'RIGHT'})
    latest_ws.format('A8:A19', {'horizontalAlignment': 'RIGHT'})

    # Agent values (columns B to agent_last_col): centered
    latest_ws.format(f'B3:{agent_last_col}5', {'horizontalAlignment': 'CENTER'})
    latest_ws.format(f'B8:{agent_last_col}19', {'horizontalAlignment': 'CENTER'})

    # Total column: bold and centered
    latest_ws.format(f'{total_col}3:{total_col}5', {
        'textFormat': {'bold': True},
        'horizontalAlignment': 'CENTER'
    })
    latest_ws.format(f'{total_col}8:{total_col}19', {
        'textFormat': {'bold': True},
        'horizontalAlignment': 'CENTER'
    })

    # Standards column: centered with background color for visibility
    latest_ws.format(f'{standards_col}3:{standards_col}5', {
        'horizontalAlignment': 'CENTER',
        'backgroundColor': {'red': 0.95, 'green': 0.95, 'blue': 0.95}
    })
    latest_ws.format(f'{standards_col}8:{standards_col}19', {
        'horizontalAlignment': 'CENTER',
        'backgroundColor': {'red': 0.95, 'green': 0.95, 'blue': 0.95}
    })

    # Metadata rows: "Report Generated:" and "Date Range:" bold
    latest_ws.format('A21', {'textFormat': {'bold': True}})
    latest_ws.format('A22', {'textFormat': {'bold': True}})

    # === Write to "History" tab ===
    print("  Writing to 'History' tab...")
    if "History" in existing_tabs:
        history_ws = spreadsheet.worksheet("History")
        # Check if this week's data already exists (avoid duplicates)
        existing_data = history_ws.get_all_values()
        if existing_data and len(existing_data) > 1:
            # Check if this week is already in the history
            existing_weeks = [row[0] for row in existing_data[1:]]  # Skip header
            if week_label in existing_weeks:
                print(f"  Week {week_label} already exists in History, skipping...")
            else:
                # Insert new rows at row 2 (after header)
                history_ws.insert_rows(history_rows_to_add, row=2)
        else:
            # Empty sheet, just add header and data
            history_rows = [history_headers] + history_rows_to_add
            history_ws.update(history_rows, 'A1')
            history_ws.format('A1:R1', {'textFormat': {'bold': True}})
    else:
        # Create new History tab
        history_ws = spreadsheet.add_worksheet(title="History", rows=1000, cols=20, index=1)
        history_rows = [history_headers] + history_rows_to_add
        history_ws.update(history_rows, 'A1')
        history_ws.format('A1:R1', {'textFormat': {'bold': True}})

    return f"https://docs.google.com/spreadsheets/d/{WEEKLY_AGENT_SHEET_ID}/edit"


def generate_email_html(
    agent_data: Dict[str, Dict[str, Any]],
    totals: Dict[str, Any],
    standards: Dict[str, Any],
    all_agents: List[str],
    start_date: datetime,
    end_date: datetime,
    is_midweek: bool = False
) -> str:
    """
    Generate HTML email content matching the Google Sheet layout.
    """
    # Build HTML table
    html = """
    <html>
    <head>
        <style>
            body { font-family: Arial, sans-serif; }
            table { border-collapse: collapse; margin: 20px 0; }
            th, td { border: 1px solid #ddd; padding: 8px 12px; text-align: center; }
            th { background-color: #f5f5f5; font-weight: bold; }
            .section-header { background-color: #e8e8e8; font-weight: bold; text-align: left !important; }
            .metric-label { text-align: right !important; }
            .total-col { font-weight: bold; background-color: #f9f9f9; }
            .standards-col { background-color: #f0f0f0; }
            .empty-row { height: 10px; }
            .metadata { color: #666; font-size: 12px; margin-top: 20px; }
        </style>
    </head>
    <body>
    """

    # Add header
    if is_midweek:
        html += f"<h2>Midweek AM Metrics and KPIs Report</h2>"
    else:
        html += f"<h2>Weekly AM Metrics and KPIs Report</h2>"

    # end_date is Monday 00:00, so subtract 1 day to show Sunday (actual last day of data)
    display_end_date = end_date - timedelta(days=1)
    html += f"<p>Date Range: {start_date.strftime('%Y-%m-%d')} to {display_end_date.strftime('%Y-%m-%d')}</p>"

    # Start table
    html += "<table>"

    # Header row
    html += "<tr><th></th>"
    for agent in all_agents:
        html += f"<th>{agent}</th>"
    html += "<th class='total-col'>Total (Actuals)</th>"
    html += "<th class='standards-col'>Standards (each AM)</th></tr>"

    # KPIs section header
    html += "<tr><td class='section-header' colspan='100%'>KPIs</td></tr>"

    # KPI rows
    kpi_metrics = [
        ("Offers Made", 'offers'),
        ("Contracts Sent", 'contracts_sent'),
        ("% Open Offers w/ <= 2 Dials After Offer", 'low_followup_pct'),
    ]
    for label, key in kpi_metrics:
        html += f"<tr><td class='metric-label'>{label}</td>"
        for agent in all_agents:
            html += f"<td>{agent_data[agent][key]}</td>"
        html += f"<td class='total-col'>{totals[key]}</td>"
        html += f"<td class='standards-col'>{standards[key]}</td></tr>"

    # Empty row
    html += "<tr class='empty-row'><td colspan='100%'></td></tr>"

    # Metrics section header
    html += "<tr><td class='section-header' colspan='100%'>Metrics</td></tr>"

    # Metrics rows
    metric_items = [
        ("Talk Time (min)", 'talk_time'),
        ("Outbound Calls", 'outbound_calls'),
        ("Connections (2+ min)", 'connections'),
        ("Connection Rate", 'connection_rate'),
        ("Unique Leads Dialed", 'unique_leads'),
        ("Unique Leads Connected", 'unique_leads_connected'),
        ("Unique Lead Connection Rate", 'unique_lead_conn_rate'),
        ("Avg Call (min)", 'avg_call_min'),
        ("Single Dial", 'single_dial_with_rate'),
        ("2x Dial", 'double_dial_with_rate'),
        ("% Open Offers w/ <=1 Connection After Offer", 'low_conn_pct'),
        ("Signed Contracts", 'signed_contracts'),
    ]
    for label, key in metric_items:
        html += f"<tr><td class='metric-label'>{label}</td>"
        for agent in all_agents:
            html += f"<td>{agent_data[agent][key]}</td>"
        html += f"<td class='total-col'>{totals[key]}</td>"
        html += f"<td class='standards-col'>{standards[key]}</td></tr>"

    html += "</table>"

    # Metadata
    html += f"""
    <div class='metadata'>
        <p>Report Generated: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')}</p>
    </div>
    </body>
    </html>
    """

    return html


def send_email_report(
    html_content: str,
    start_date: datetime,
    end_date: datetime,
    is_midweek: bool = False
) -> bool:
    """
    Send the report via email.
    Returns True if successful, False otherwise.
    """
    if not EMAIL_PASSWORD:
        print("WARNING: EMAIL_PASSWORD not set, skipping email")
        return False

    # Determine subject line
    if is_midweek:
        # Wednesday: use the current date
        subject_date = datetime.now(EASTERN_TZ).strftime('%B %d, %Y')
        subject = f"Midweek AM Metrics and KPIs Report - {subject_date}"
    else:
        # Monday: use the Saturday of the previous week (end_date is Sunday, so subtract 1 day)
        # end_date is the start of the current week (Monday 00:00), so Saturday is end_date - 2 days
        # Actually, for previous week report, end_date is Sunday 23:59 or Monday 00:00
        # We want the Saturday, which is 1 day before Sunday
        saturday_date = end_date - timedelta(days=1)
        if saturday_date.weekday() != 5:  # If not Saturday, find the previous Saturday
            days_since_saturday = (saturday_date.weekday() + 2) % 7
            saturday_date = saturday_date - timedelta(days=days_since_saturday)
        subject_date = saturday_date.strftime('%B %d, %Y')
        subject = f"Weekly AM Metrics and KPIs Report - For the week ending {subject_date}"

    try:
        # Create message
        message = MIMEMultipart("alternative")
        message["From"] = EMAIL_FROM
        message["To"] = ", ".join(EMAIL_TO)
        message["Cc"] = ", ".join(EMAIL_CC)
        message["Subject"] = subject

        # Attach HTML content
        html_part = MIMEText(html_content, "html")
        message.attach(html_part)

        # All recipients (To + Cc)
        all_recipients = EMAIL_TO + EMAIL_CC

        # Send email
        context = ssl.create_default_context()
        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:
            server.starttls(context=context)
            server.login(EMAIL_FROM, EMAIL_PASSWORD)
            server.sendmail(EMAIL_FROM, all_recipients, message.as_string())

        print(f"Email sent successfully: {subject}")
        return True

    except Exception as e:
        print(f"ERROR: Failed to send email: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='Generate weekly agent performance report')
    parser.add_argument(
        '--days',
        type=int,
        default=None,
        help='Number of days to include in report (overrides week boundaries)'
    )
    parser.add_argument(
        '--previous-week',
        action='store_true',
        help='Report on the previous full week (Mon-Sun) instead of current week'
    )
    parser.add_argument(
        '--no-sheet',
        action='store_true',
        help='Skip writing to Google Sheets (for mid-week email-only reports)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Print report to console without writing to Google Sheets'
    )
    parser.add_argument(
        '--send-email',
        action='store_true',
        help='Send report via email'
    )
    args = parser.parse_args()

    # Determine report type for logging
    now = datetime.now(timezone.utc)
    is_monday = now.weekday() == 0

    if args.days is not None:
        print(f"Generating agent report for the last {args.days} days...")
    elif args.previous_week:
        print("Generating agent report for previous week (Mon-Sun)...")
    elif is_monday:
        print("Monday detected - generating report for previous week (Mon-Sun)...")
    else:
        print("Generating agent report for current week (Mon-Sun) so far...")

    # Calculate date range
    start_date, end_date = get_date_range(args.days, args.previous_week)
    print(f"Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")

    # Get stage metrics from database
    print("Querying stage metrics from database...")
    stage_metrics = query_stage_metrics(start_date, end_date)
    print(f"Found metrics for {len(stage_metrics)} agents")

    # Get call metrics from FUB API
    print("Fetching FUB users...")
    fub_users = get_fub_users()
    print(f"Found {len(fub_users)} FUB users")

    print("Querying call metrics from FUB API...")
    call_metrics = query_call_metrics(start_date, end_date, fub_users)
    print(f"Retrieved call data for {len(call_metrics)} users")

    # Get open offers metrics (follow-up and connection percentages)
    print("Querying open offers follow-up metrics...")
    open_offers_metrics = query_open_offers_metrics(FUB_API_KEY)
    total_open = sum(m['total'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
    total_low_followup = sum(m['low_followup_count'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
    total_low_conn = sum(m['low_connection_count'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
    print(f"Found {total_open} open offers, {total_low_followup} with <=2 follow-up dials, {total_low_conn} with <=1 connection")

    def print_report_to_console(title_suffix=""):
        """Helper to print report data to console."""
        print("\n" + "=" * 100)
        print(f"AGENT PERFORMANCE REPORT{title_suffix}")
        print(f"Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")
        print("=" * 100)

        # Print header rows (split into two lines for readability)
        print(f"\n{'Agent':<25} {'Offers':<7} {'Contracts':<10} {'Under K':<8} {'Closed':<7} {'Outbound':<9} {'Leads':<7} {'Connected':<10} {'Convos':<7} {'ConnRate':<9} {'Talk(m)':<8} {'Avg(m)':<7} {'Single':<7} {'2x':<4} {'3x':<4}")
        print("-" * 140)

        all_agents = set(stage_metrics.keys()) | set(call_metrics.keys())
        for agent in sorted(all_agents):
            stage_data = stage_metrics.get(agent, {})
            offers = stage_data.get("ACQ - Offers Made", 0)
            contracts = stage_data.get("ACQ - Contract Sent", 0)
            under_contract = stage_data.get("ACQ - Under Contract", 0)
            closed = stage_data.get("Closed", 0) + stage_data.get("ACQ - Closed Won", 0)

            call_data = call_metrics.get(agent, {})
            outbound_calls = call_data.get('outbound_calls', 0)
            unique_leads = call_data.get('unique_leads_dialed', 0)
            unique_connected = call_data.get('unique_leads_connected', 0)
            connected = call_data.get('connected', 0)
            conversations = call_data.get('conversations', 0)
            long_call_durations = call_data.get('long_call_durations', [])
            avg_call_min = round(sum(long_call_durations) / len(long_call_durations) / 60, 1) if long_call_durations else 0
            talk_time = call_data.get('talk_time_min', 0)
            connection_rate = f"{round(connected / outbound_calls * 100)}%" if outbound_calls > 0 else "0%"
            single_dial = call_data.get('single_dial_calls', 0)
            double_seq = call_data.get('double_dial_sequences', 0)
            triple_seq = call_data.get('triple_dial_sequences', 0)

            # Truncate long agent names for display
            display_name = agent[:24] if len(agent) > 24 else agent
            print(f"{display_name:<25} {offers:<7} {contracts:<10} {under_contract:<8} {closed:<7} {outbound_calls:<9} {unique_leads:<7} {unique_connected:<10} {conversations:<7} {connection_rate:<9} {talk_time:<8} {avg_call_min:<7} {single_dial:<7} {double_seq:<4} {triple_seq:<4}")

    # Prepare agent data for email (same logic as write_to_google_sheets)
    def prepare_email_data():
        """Prepare data structures needed for email."""
        all_agents_set = set(stage_metrics.keys()) | set(call_metrics.keys())
        all_agents_set.discard('Unassigned')
        if INCLUDED_AGENTS:
            agents_list = [a for a in sorted(all_agents_set) if a in INCLUDED_AGENTS]
        else:
            agents_list = sorted(all_agents_set)

        agent_data = {}
        for agent in agents_list:
            stage_data = stage_metrics.get(agent, {})
            offers = stage_data.get("ACQ - Offers Made", 0)
            contracts_sent = stage_data.get("ACQ - Contract Sent", 0)
            signed_contracts = stage_data.get("ACQ - Under Contract", 0)

            call_data = call_metrics.get(agent, {})
            outbound_calls = call_data.get('outbound_calls', 0)
            unique_leads = call_data.get('unique_leads_dialed', 0)
            unique_leads_connected = call_data.get('unique_leads_connected', 0)
            connections = call_data.get('conversations', 0)
            long_call_durations = call_data.get('long_call_durations', [])
            avg_call_min = round(sum(long_call_durations) / len(long_call_durations) / 60, 1) if long_call_durations else 0
            talk_time = call_data.get('talk_time_min', 0)
            connection_rate = f"{round(connections / outbound_calls * 100)}%" if outbound_calls > 0 else "0%"
            unique_lead_conn_rate = f"{round(unique_leads_connected / unique_leads * 100)}%" if unique_leads > 0 else "0%"
            single_dial = call_data.get('single_dial_calls', 0)
            single_dial_answered = call_data.get('single_dial_answered', 0)
            double_dial = call_data.get('double_dial_sequences', 0)
            double_dial_answered = call_data.get('double_dial_answered', 0)

            single_dial_rate = round(single_dial_answered / single_dial * 100) if single_dial > 0 else 0
            double_dial_rate = round(double_dial_answered / double_dial * 100) if double_dial > 0 else 0
            single_dial_with_rate = f"{single_dial} ({single_dial_rate}%)"
            double_dial_with_rate = f"{double_dial} ({double_dial_rate}%)"

            agent_offer_metrics = open_offers_metrics.get(agent, {}) if open_offers_metrics else {}
            low_followup_pct = agent_offer_metrics.get('low_followup_pct', '0%')
            low_conn_pct = agent_offer_metrics.get('low_connection_pct', '0%')

            agent_data[agent] = {
                'offers': offers,
                'contracts_sent': contracts_sent,
                'low_followup_pct': low_followup_pct,
                'talk_time': talk_time,
                'outbound_calls': outbound_calls,
                'connections': connections,
                'connection_rate': connection_rate,
                'unique_leads': unique_leads,
                'unique_leads_connected': unique_leads_connected,
                'unique_lead_conn_rate': unique_lead_conn_rate,
                'avg_call_min': avg_call_min,
                'single_dial_with_rate': single_dial_with_rate,
                'double_dial_with_rate': double_dial_with_rate,
                'low_conn_pct': low_conn_pct,
                'signed_contracts': signed_contracts,
                'long_call_total_sec': sum(long_call_durations),
                'long_call_count': len(long_call_durations),
            }

        # Calculate totals
        totals = {
            'offers': sum(agent_data[a]['offers'] for a in agents_list),
            'contracts_sent': sum(agent_data[a]['contracts_sent'] for a in agents_list),
            'talk_time': sum(agent_data[a]['talk_time'] for a in agents_list),
            'outbound_calls': sum(agent_data[a]['outbound_calls'] for a in agents_list),
            'connections': sum(agent_data[a]['connections'] for a in agents_list),
            'unique_leads': sum(agent_data[a]['unique_leads'] for a in agents_list),
            'unique_leads_connected': sum(agent_data[a]['unique_leads_connected'] for a in agents_list),
            'single_dial': sum(int(agent_data[a]['single_dial_with_rate'].split()[0]) for a in agents_list),
            'double_dial': sum(int(agent_data[a]['double_dial_with_rate'].split()[0]) for a in agents_list),
            'signed_contracts': sum(agent_data[a]['signed_contracts'] for a in agents_list),
            'long_call_total_sec': sum(agent_data[a]['long_call_total_sec'] for a in agents_list),
            'long_call_count': sum(agent_data[a]['long_call_count'] for a in agents_list),
        }
        totals['connection_rate'] = f"{round(totals['connections'] / totals['outbound_calls'] * 100)}%" if totals['outbound_calls'] > 0 else "0%"
        totals['unique_lead_conn_rate'] = f"{round(totals['unique_leads_connected'] / totals['unique_leads'] * 100)}%" if totals['unique_leads'] > 0 else "0%"
        totals['avg_call_min'] = round(totals['long_call_total_sec'] / totals['long_call_count'] / 60, 1) if totals['long_call_count'] > 0 else 0
        totals['single_dial_with_rate'] = totals['single_dial']
        totals['double_dial_with_rate'] = totals['double_dial']

        total_open_offers = sum(m['total'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
        total_low_followup_count = sum(m['low_followup_count'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
        total_low_conn_count = sum(m['low_connection_count'] for m in open_offers_metrics.values()) if open_offers_metrics else 0
        totals['low_followup_pct'] = f"{round(total_low_followup_count / total_open_offers * 100)}%" if total_open_offers > 0 else "0%"
        totals['low_conn_pct'] = f"{round(total_low_conn_count / total_open_offers * 100)}%" if total_open_offers > 0 else "0%"

        standards = {
            'offers': 18,
            'contracts_sent': 4,
            'low_followup_pct': "< 20%",
            'talk_time': 220,
            'outbound_calls': 160,
            'connections': 30,
            'connection_rate': "-",
            'unique_leads': 50,
            'unique_leads_connected': "-",
            'unique_lead_conn_rate': "-",
            'avg_call_min': "-",
            'single_dial_with_rate': "-",
            'double_dial_with_rate': "-",
            'low_conn_pct': "< 75%",
            'signed_contracts': 1,
        }

        return agent_data, totals, standards, agents_list

    if args.dry_run:
        # Dry run - print to console only
        print_report_to_console(" (DRY RUN)")
        print("\n(Dry run - no data written to Google Sheets)")
    elif args.no_sheet:
        # Mid-week email-only run - no Google Sheet tab
        print_report_to_console(" (MID-WEEK)")
        print("\n(Mid-week report - no Google Sheet tab created)")
        if args.send_email:
            print("Preparing and sending email report...")
            agent_data, totals, standards, agents_list = prepare_email_data()
            html_content = generate_email_html(agent_data, totals, standards, agents_list, start_date, end_date, is_midweek=True)
            send_email_report(html_content, start_date, end_date, is_midweek=True)
    else:
        # Full report - write to Google Sheets
        print("Writing report to Google Sheets...")
        sheet_url = write_to_google_sheets(stage_metrics, call_metrics, start_date, end_date, open_offers_metrics)
        print(f"\nReport created successfully!")
        print(f"View report: {sheet_url}")
        if args.send_email:
            print("Preparing and sending email report...")
            agent_data, totals, standards, agents_list = prepare_email_data()
            html_content = generate_email_html(agent_data, totals, standards, agents_list, start_date, end_date, is_midweek=False)
            send_email_report(html_content, start_date, end_date, is_midweek=False)


if __name__ == '__main__':
    main()
